"""
embed_words.py â€” FINAL VERSION
âœ” tqdm é€²åº¦æ¢
âœ” ETA é ä¼°
âœ” API è‡ªå‹•é‡è©¦
âœ” Railway MySQL URL æ”¯æ´
"""

import os
import json
import time
from urllib.parse import urlparse

import pandas as pd
import pymysql
from dotenv import load_dotenv
from openai import OpenAI
from tqdm import tqdm

# ==============================
# è®€å–ç’°å¢ƒè®Šæ•¸
# ==============================
load_dotenv()

MYSQL_URL = os.getenv("MYSQL_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not MYSQL_URL:
    raise RuntimeError("âŒ ç¼ºå°‘ MYSQL_URLï¼Œè«‹åœ¨ .env è¨­å®š")
if not OPENAI_API_KEY:
    raise RuntimeError("âŒ ç¼ºå°‘ OPENAI_API_KEYï¼Œè«‹åœ¨ .env è¨­å®š")

print("ğŸ” è§£æ MySQL_URL =", MYSQL_URL)

url = urlparse(MYSQL_URL)
MYSQL_HOST = url.hostname
MYSQL_PORT = url.port
MYSQL_USER = url.username
MYSQL_PASSWORD = url.password
MYSQL_DB = url.path[1:]

print(f"ğŸ§­ Host={MYSQL_HOST}, Port={MYSQL_PORT}, User={MYSQL_USER}, DB={MYSQL_DB}")

client = OpenAI(api_key=OPENAI_API_KEY)

# ==============================
# MySQL é€£ç·š
# ==============================
def db_conn():
    return pymysql.connect(
        host=MYSQL_HOST,
        port=MYSQL_PORT,
        user=MYSQL_USER,
        password=MYSQL_PASSWORD,
        database=MYSQL_DB,
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor,
        autocommit=False,
    )

db = db_conn()
print("âœ… æˆåŠŸé€£ç·š Railway MySQL")

# ==============================
# å»ºç«‹ word_embeddings è³‡æ–™è¡¨
# ==============================
TABLE_SQL = """
CREATE TABLE IF NOT EXISTS word_embeddings (
    id INT AUTO_INCREMENT PRIMARY KEY,
    word_id INT NOT NULL,
    word VARCHAR(255) NOT NULL,
    embedding JSON NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE KEY uq_word_id (word_id),
    FOREIGN KEY (word_id) REFERENCES words(id) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
"""

with db.cursor() as cursor:
    cursor.execute(TABLE_SQL)
db.commit()
print("âœ… å·²ç¢ºèª word_embeddings è³‡æ–™è¡¨å­˜åœ¨")

# ==============================
# è®€ CSV
# ==============================
df = pd.read_csv("words.csv")
print(f"ğŸ“„ CSV è®€å–æˆåŠŸï¼šå…± {len(df)} ç­†")

col_word = "å–®å­—" if "å–®å­—" in df.columns else "word"

# ==============================
# å–å¾— DB ç›®å‰æœ‰å¤šå°‘è³‡æ–™
# ==============================
with db.cursor() as cursor:
    cursor.execute("SELECT COUNT(*) AS c FROM words")
    words_count = cursor.fetchone()["c"]

    cursor.execute("SELECT COUNT(*) AS c FROM word_embeddings")
    embed_count = cursor.fetchone()["c"]

print(f"ğŸ“Š words è¡¨ = {words_count} ç­†")
print(f"ğŸ“Š word_embeddings è¡¨ = {embed_count} ç­†\n")

# ==============================
# æ‰¾éœ€è¦ç”¢ç”Ÿ embedding çš„å–®å­— (å« tqdm)
# ==============================
to_embed = []

with db.cursor() as cursor:
    for _, row in tqdm(df.iterrows(), total=len(df), desc="ğŸ” æª¢æŸ¥éœ€è¦ embedding çš„å–®å­—"):
        word = str(row[col_word]).strip()
        if not word:
            continue

        cursor.execute("SELECT id FROM words WHERE word=%s", (word,))
        w = cursor.fetchone()
        if not w:
            continue

        word_id = w["id"]

        cursor.execute("SELECT id FROM word_embeddings WHERE word_id=%s", (word_id,))
        if cursor.fetchone():
            continue

        to_embed.append({"word": word, "word_id": word_id})

print(f"\nğŸ§® ç¸½å…±éœ€è¦ embedding çš„å–®å­—ï¼š{len(to_embed)}")

if len(to_embed) == 0:
    print("ğŸ‘ æ‰€æœ‰ embedding éƒ½å·²å­˜åœ¨ï¼Œä¸éœ€è·‘ï¼")
    db.close()
    exit(0)

# ==============================
# é–‹å§‹ç”¢ç”Ÿ embeddingsï¼ˆå« ETAï¼‰
# ==============================
MODEL = "text-embedding-3-small"
BATCH = 50
total = len(to_embed)
processed = 0
start = time.time()

def eta(start, done, total):
    if done == 0:
        return "è¨ˆç®—ä¸­..."
    speed = done / (time.time() - start)
    left = (total - done) / speed
    return f"{left:.1f} ç§’"

with db.cursor() as cursor:
    for i in range(0, total, BATCH):
        batch = to_embed[i:i+BATCH]
        words_list = [x["word"] for x in batch]

        print(f"\nğŸš€ Embedding {i+1} ~ {i+len(batch)} / {total}")
        print("â³ ETA:", eta(start, processed, total))

        # ====== å‘¼å« APIï¼ˆæœ€å¤šé‡è©¦ 3 æ¬¡ï¼‰ ======
        for retry in range(3):
            try:
                resp = client.embeddings.create(
                    model=MODEL,
                    input=words_list
                )
                break
            except Exception as e:
                print(f"âš ï¸ API éŒ¯èª¤ï¼Œé‡è©¦ {retry+1}/3ï¼š", e)
                time.sleep(2)
        else:
            raise RuntimeError("âŒ API é‡è©¦ 3 æ¬¡ä»å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯æˆ– API Key")

        # ====== å¯«å…¥ DB ======
        for item, emb in zip(batch, resp.data):
            cursor.execute(
                """
                INSERT INTO word_embeddings (word_id, word, embedding)
                VALUES (%s, %s, %s)
                ON DUPLICATE KEY UPDATE embedding=VALUES(embedding)
                """,
                (item["word_id"], item["word"], json.dumps(emb.embedding)),
            )

        db.commit()

        processed += len(batch)
        percent = processed / total * 100
        print(f"âœ… é€²åº¦ï¼š{processed}/{total} ({percent:.2f}%)")

db.close()
print("\nğŸ‰ å…¨éƒ¨ embeddings ç”Ÿæˆå®Œç•¢ï¼")